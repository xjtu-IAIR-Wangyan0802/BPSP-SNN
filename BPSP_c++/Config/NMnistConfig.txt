#Comment#
#NON_LINEARITY = NL_SIGMOID , NL_TANH , NL_RELU#
IS_GRADIENT_CHECKING = false;   #is true when debug#
BOOST_METHOD = true;            #allow boost weight train#
EFFECT_RATIO = true;            #use e^k_{i|j}/o^{k-1}_j for estimate the grad of syn effect#
                                #need to set batch = 1 in this case#

OPTIMIZER = adam;                # use adam as the optimizer , by default is sgd with momentum #
DYNAMIC_THRESHOLD = false;       # allow dynamic threshold#
SHOWIMAGE = false;              #show the images after transformation#
TEST_EPOCH = 200;                 #the period to get the test dataset's error rate#

WHITE_NOISE = 0.0;  
LAMBDA_REG  = 10;               # param for weight regularization #
BETA_REG    = 0.01;               

WEIGHT_LIMIT= 8.0;

BATCH_SIZE = 1;
CHANNELS = 1;                   #1, 3, 4#
END_TIME = 540;                 #The spike train duration#


TRAIN_PER_CLASS = -1;               # number of train/test samples per class #
TEST_PER_CLASS = -1;


TRAIN_DATA_PATH=/wy/dataset_wy/3528_600/3528_600_stable/train_0.40;
TEST_DATA_PATH=/wy/dataset_wy/3528_600/3528_600_stable/test;

[
LAYER = DATASPIKING;
NAME  = data;
NUM_NEURONS = 3528;
]

[
LAYER = SPIKING;
NAME  = hidden_0;
NUM_NEURONS = 800;
INPUT = data;
VTH = 15;
T_REFRAC = 2;
TAU_M = 64;
TAU_S = 8;
initW = 1;
initType = Bernoulli;
]


[
LAYER = SPIKING;
NUM_CLASSES = 10;
NAME  = output;
NUM_NEURONS = 10;
INPUT = hidden_0;
VTH = 15;
T_REFRAC = 2;
TAU_M = 64;
TAU_S = 8;
initW = 1;
initType = Bernoulli;
laterialType = LOCAL_INHIBITION;
localInbStrength = 1;
DESIRED_LEVEL = 35;
UNDESIRED_LEVEL = 5;
MARGIN = 5;
]

